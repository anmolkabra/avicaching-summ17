\chapter{Introduction} \label{sec:Introduction}
Optimizing predictive models on datasets obtained from citizen-science projects can be computationally expensive as these datasets grow in size. Consequently, running models based on Multi-layered Neural Networks, Integer Programming and other optimization routines can become more computationally difficult as the number of parameters increase, despite using the faster Central Processing Units (CPUs) in the market. Incidentally, it becomes difficult for citizen-science projects to scale if the organizers use CPUs to run neural networks, which require extensive tensor operations. However, Graphical Processing Units (GPUs), which offer numerous cores to parallelize computation, can outperform CPUs in computing such predictive models if these models \textit{heavily} rely on large-scale tensor operations []. By using GPUs over CPUs to accelerate computation on a citizen-science project, the model could achieve better optimization in less time, enabling the project to scale.

\section{Avicaching} \label{sec:Avicaching}
Part of the eBird project, which aims to ``maximize the utility and accessibility of the vast numbers of bird observations made each year by recreational and professional bird watchers'' [cite website], Avicaching is a incentive-driven game trying to homogenize the spatial distribution of citizens' (agents') observations \cite{Xue2016Avi1}. Since the dataset of agents' observations in eBird is geographically heterogeneous (concentrated in some places like cities and sparse in others), Avicaching homogenizes the observation set by placing rewards at and attracting agents to under-sampled locations \cite{Xue2016Avi1}. For the agents, collecting rewards increases their `utility' (excitement, fun etc.), while for the organizers, a more homogeneous observation dataset means better sampling and higher confidence in using it to deploy other models. 

To accomplish this task of specifying rewards at different locations based on the historical records of observations, Avicaching would learn how agents change their behavior when a certain sample of rewards were applied to the set of locations, and then redistribute rewards across the locations based on those learned parameters \cite{Xue2016Avi2}. This requirement naturally translates into a predictive optimization problem, implemented using multi-layered neural networks and linear programming.

\section{Important Questions} \label{sec:Important Questions}
Although the previously devised solutions to Avicaching were conceptually effective \cite{Xue2016Avi1, Xue2016Avi2}, using CPUs to solve Mixed Integer Programming and (even) shallow neural networks made the models impractical to scale. Solving the problems faster would have also allowed organizers to find better results (more optimized). These concerns, which form the pivot for our research, are concisely described below.

\subsection{Solving Faster} \label{sec:Important Questions - Solving Faster}
We were interested in using GPUs to run our optimization models because of their capability to accelerate problems based on large tensor operations. Newer generation NVIDIA GPUs, equipped with thousands of CUDA (NVIDIA's parallel computing API) cores \cite{NVIDIA}, could have empowered Avicaching's organizers to scale the game, if the game was computed using simple arithmetic operations on tensors, rather than using conditional logic (see \Cref{sec:Computation Using GPUs}). Since even the faster CPUs - in the range of Intel Core i7 chipsets - are sequential in processing and do not provide as comparable parallel processing\footnote{CPUs often have multiple cores nowadays, but very few compared to what many GPUs have. We use Intel i7-7700K (4 cores) CPU and NVIDIA Quadro P4000 (1792 CUDA cores) for our tests.} as GPUs do, we seek to solve the problem much faster using GPUs. \textbf{But how much faster?}

\subsection{Better Results} \label{sec:Important Questions - Better Results}
The previous model, for learning the parameters in agents' change of behavior on a fixed set of rewards, delivered predictions that differed 26\% from Ground Truth \cite[Table 1]{Xue2016Avi2}. This model was then used to redistribute rewards in a budget. If we could get closer to the Ground Truth, i.e., better learn the parameters for the change, we could redistribute rewards with superior prediction/accuracy. Since the organizers need the \textit{best} distribution of rewards, we will need a set of learned parameters that is closer to the Ground Truth (in terms of Normalized Mean Squared Error \cite[Section 4.2]{Xue2016Avi2}). In a gist, we aim to \textbf{learn the parameters more suitably}, and find the \textbf{best allocation of rewards?}

\subsection{Adjusting the Model's Features} \label{sec:Important Questions - Adjusting the Model's Features}
Once our model starts delivering better results than the previously devised models, one thinks if some characteristics of the model (hyper-parameters such as learning rate) can be changed to get more preferable results (one could also build a better model). While a goal of ``getting better results'' is an unending struggle, there is a trade-off with practicality as these adjustments take time and computation power to test - and we didn't have unlimited resources. Therefore, we asked if one could \textbf{reasonably adjust hyper-parameters to improve performance and optimization.}

\section{Computation Using GPUs} \label{sec:Computation Using GPUs}
The use of GPUs has changed drastically in the last decade - from rendering superior graphics on monitors to parallelizing general matrix operations, speeding up matrix-based algorithms. Companies like NVIDIA are now providing General Purpose GPUs (GPGPUs) that are capable of executing parallel algorithms using thousands of cores and threads. Furthermore, by working with dedicated for parallel programming APIs like CUDA, one can handle a GPU's threads more efficiently and optimize an task's datapath. To give an overview of GPUs, we briefly describe an NVIDIA GPU's architecture, instruction set and best practices for optimization. Although we do not implement the CUDA backend manually and use Pytorch's implementation, understanding the basics of the processor can be helpful for designing our models.

\subsection{GPU Architecture}


\subsection{Avoiding Specific Instructions in GPUs}
%\subsubsection{}